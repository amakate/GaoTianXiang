{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GiSleepNet_GUI_for_public_version1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMsu9lQ0Cyot1vG1aKauIxN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM9hJAyn561b"
      },
      "source": [
        "\n",
        "import os\n",
        "\n",
        "import tkinter as tk\n",
        "from tkinter import *\n",
        "from tkinter import filedialog\n",
        "import tkinter.ttk as ttk\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "#from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk\n",
        "import datetime\n",
        "\n",
        "from multiprocessing import Process\n",
        "import numpy as np\n",
        "from numpy.fft import fftn, ifftn, fftfreq\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "#import matplotlib as mpl\n",
        "import sqlalchemy\n",
        "#from matplotlib.ticker import ScalarFormatter\n",
        "import sqlalchemy\n",
        "from scipy.fftpack import fft, ifft\n",
        "from PIL import ImageTk,Image\n",
        "\n",
        "import tensorflow as tf\n",
        "print('Tensorflow version:{}'.format(tf.__version__))\n",
        "#import matplotlib.pyplot as pltrandom\n",
        "import pathlib\n",
        "from tkinter import END\n",
        "from PIL import ImageTk,Image\n",
        "from tkinter import filedialog\n",
        "\n",
        "\n",
        "root = tk.Tk()\n",
        "root.title('Welcome to GI-SleepNet')\n",
        "root.iconbitmap('C:/Users/gtxde/Downloads/favicon.ico')\n",
        "root.geometry('1500x1000+10+10')\n",
        "\n",
        "tab_main=ttk.Notebook()\n",
        "tab_main.place(relx=0.02, rely=0.02, relwidth=0.887, relheight=0.876)\n",
        "\n",
        "tab1=tk.Frame(tab_main)\n",
        "\n",
        "\n",
        "\n",
        "tab1.place(x=0,y=30)\n",
        "tab_main.add(tab1,text='Calculation Processing& Plotting')\n",
        "\n",
        "\n",
        "def open_folder1():\n",
        "    global Folderpath1\n",
        "    Folderpath1 = filedialog.askdirectory(title = \"select the folder\",initialdir ='C:/')\n",
        "    print (Folderpath1)\n",
        "    outfile_e.insert(0,Folderpath1)\n",
        "    start_time = datetime.datetime.now()\n",
        "    global start_time_str\n",
        "    start_time_str = str(start_time)\n",
        "    \n",
        "    start_time_str = start_time_str.replace(':','-')\n",
        "    \n",
        "    start_time_str =start_time_str[:20]\n",
        "    global png_folder\n",
        "    png_folder = Folderpath1 + '/'+ start_time_str\n",
        "    print(png_folder)\n",
        "    return png_folder\n",
        "\n",
        "'''\n",
        "def open_folder2():\n",
        "    global Folderpath2\n",
        "    Folderpath2 = filedialog.askdirectory(title = \"select the folder\",initialdir ='C:/')\n",
        "    print (Folderpath2)\n",
        "    e2.insert(0,Folderpath2)\n",
        "    return\n",
        "\n",
        "'''\n",
        "\n",
        "def open_file1():\n",
        "    global filepath1\n",
        "    filepath1 = filedialog.askopenfilename( )\n",
        "    print (filepath1)\n",
        "    dat_e.insert(0,filepath1)\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "b_outfile= tk.Button(tab1, text=\"select the folder\",width=25,command = open_folder1)\n",
        "b_outfile.grid(row=3, column=0)\n",
        "\n",
        "outfile_e = tk.Entry(tab1, width=100, borderwidth=10)\n",
        "outfile_e.grid(row=3, column=1)\n",
        "\n",
        "\n",
        "'''\n",
        "button2_open_folder= tk.Button(tab1, text=\"select the folder\",width=25,command = open_folder2)\n",
        "button2_open_folder.grid(row=1, column=0)\n",
        "\n",
        "e2 = tk.Entry(tab1, width=100, borderwidth=10)\n",
        "e2.grid(row=1, column=1)\n",
        "'''\n",
        "\n",
        "\n",
        "b_open_folder= tk.Button(tab1, text=\"select the dat file\",width=25,command = open_file1)\n",
        "b_open_folder.grid(row=0, column=0)\n",
        "\n",
        "\n",
        "dat_e = tk.Entry(tab1, width=100, borderwidth=10)\n",
        "dat_e.grid(row=0, column=1)\n",
        "\n",
        "\n",
        "\n",
        "eeg_e = tk.Entry(tab1, width=10)\n",
        "eeg_e.grid(row=1, column=1,sticky=tk.W)\n",
        "emg_e = tk.Entry(tab1, width=10)\n",
        "emg_e.grid(row=2, column=1,sticky=tk.W)\n",
        "\n",
        "\n",
        "label_EEG = tk.Label(tab1, text=\"channel number of EEG:\")\n",
        "label_EEG.grid(row=1, column=0)\n",
        "\n",
        "label_EMG = tk.Label(tab1, text=\"channelnumber of EMG:\")\n",
        "label_EMG.grid(row=2, column=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_new_file(path):\n",
        "    \n",
        "    \n",
        "    \n",
        "    folder = os.path.exists(path)\n",
        "    if not folder:\n",
        "        os.makedirs(path)\n",
        "        print('new')\n",
        "    else:\n",
        "        print('already')\n",
        "    \n",
        "    savefolder_e.insert(0,'your output figure folder    ['+ png_folder + ']   has been created just now')\n",
        "    #savefolder_e.insert(0,'your folder has been created just now')\n",
        "    return\n",
        "\n",
        "\n",
        "a = tk.Button(tab1, text=\"create folder\",width=90, borderwidth=10,command = lambda: create_new_file(png_folder))\n",
        "a.grid(row=6, column=1)\n",
        "\n",
        "\n",
        "\n",
        "savefolder_e = tk.Entry(tab1, width=100, borderwidth=10)\n",
        "savefolder_e.grid(row=7, column=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def preprocessing_for_DAT(datname):\n",
        "     analy_e.insert(0,'this takes a little time,please wait~')\n",
        "     raw = np.fromfile(datname, dtype='int16')\n",
        "     chanel_len = int(len(raw)/16)\n",
        "     allchanels=raw.reshape(chanel_len,16)\n",
        "     global emg6\n",
        "     global c2\n",
        "     emg6=allchanels[:,int(emg_e.get())]\n",
        "     c2=allchanels[:,int(eeg_e.get())]\n",
        "     \n",
        "     raw_len = len(raw)\n",
        "     long = int(raw_len/16/1000)+1\n",
        "     yu = long*1000-chanel_len\n",
        "     \n",
        "     global long_epoch\n",
        "     long_epoch = int(long/20)\n",
        "     \n",
        "     df2= pd.DataFrame(np.random.randn(1,yu))\n",
        "     df12 = pd.DataFrame(c2).T\n",
        "     df32 = pd.concat([df12, df2], axis=1, join_axes=[df12.index])\n",
        "     np12=df32.values[:, :]\n",
        "     np12=np12.reshape([long, 1000])\n",
        "     df42 = pd.DataFrame(np12)\n",
        "     fftdata2=fft(df42)\n",
        "     df62=abs(fftdata2)**2\n",
        "     df72=df62/1000000000\n",
        "     df82 = pd.DataFrame(df72)\n",
        "     df82=df82.T\n",
        "     df82_50=df82.iloc[0:50,:]\n",
        "     analy_e.delete(0, END)\n",
        "     analy_e.insert(0,'working hard')\n",
        "     print(df82_50)\n",
        "     from sklearn.preprocessing import MinMaxScaler\n",
        "     scaled_features = MinMaxScaler().fit_transform(df82_50.values)\n",
        "     global scaled_features_df\n",
        "     scaled_features_df = pd.DataFrame(scaled_features, index=df82_50.index, columns=df82_50.columns)\n",
        "     print(scaled_features_df)\n",
        "     analy_e.delete(0, END)\n",
        "     analy_e.insert(0,'the analyasis in over')\n",
        "     return emg6, scaled_features_df\n",
        "\n",
        "\n",
        "start = tk.Button(tab1, text=\"Start Analyzing Data\",width=90, borderwidth=10,command = lambda: preprocessing_for_DAT(filepath1))\n",
        "start.grid(row=8, column=1)\n",
        "\n",
        "analy_e = tk.Entry(tab1, width=100, borderwidth=10)\n",
        "analy_e.grid(row=9, column=1)\n",
        "\n",
        "\n",
        "def plot1(file_png):\n",
        "    for i in range(2,long_epoch,1):\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     z=\"%07d\"%i\n",
        "\n",
        "         \n",
        "     b\n",
        "     ax1=fig.add_subplot(2,1,1)\n",
        "     ax1.plot(emg6[(i-2)*20000:i*20000],color='black')\n",
        "     ax1.set_xlim(0,40000)\n",
        "     ax1.set_ylim(-4100,4100)\n",
        "\n",
        "     ax2=fig.add_subplot(2,1,2)\n",
        "     power = scaled_features_df.iloc[0:20,(i-2)*20:i*20]\n",
        "     ax2=sns.heatmap(power,vmin=0,vmax=1,cmap=\"gray\",square=True).invert_yaxis()\n",
        " \n",
        "     #plt.savefig('emg&eeg44#'+'h'+str(p)+'m'+str(r)+'e'+str(rownum)+'.png') \n",
        "     plt.savefig(file_png +'/EMG&EEGs'+'i'+str(z)+'.png')\n",
        "     \n",
        "     if i == long_epoch-1 :\n",
        "         plot_e.delete(0, END)\n",
        "         plot_e.insert(0,'the plot is finished')\n",
        "     plt.clf()\n",
        "     plt.close()\n",
        "\n",
        "\n",
        "\n",
        "def plot2(file_png):\n",
        "    for i in range(2,long_epoch,1):\n",
        "\n",
        "     z=\"%07d\"%i\n",
        "\n",
        "     fig=plt.figure(figsize=(24,8))\n",
        "     ax1=fig.add_subplot(2,1,1)\n",
        "     ax1.plot(emg6[(i-2)*20000:i*20000],color='black')\n",
        "     ax1.set_xlim(0,40000)\n",
        "     ax1.set_ylim(-4100,4100)\n",
        "\n",
        "     ax2=fig.add_subplot(2,1,2)\n",
        "     ax2.plot(c2[(i-2)*20000:i*20000],color='black')\n",
        "     ax2.set_xlim(0,40000)\n",
        "     ax2.set_ylim(-4100,4100)\n",
        " \n",
        "     #plt.savefig('emg&eeg44#'+'h'+str(p)+'m'+str(r)+'e'+str(rownum)+'.png') \n",
        "     plt.savefig(file_png +'/EMG&EEG'+'i'+str(z)+'.png')\n",
        "     if i == long_epoch-1 :\n",
        "         plot_e.delete(0, END)\n",
        "         plot_e.insert(0,'the plot is finished')\n",
        "     plt.clf()\n",
        "     plt.close()\n",
        "\n",
        "\n",
        "\n",
        "def plot3(file_png):\n",
        "    for i in range(2,long_epoch,1):\n",
        "\n",
        "\n",
        "     z=\"%07d\"%i\n",
        "\n",
        "     fig=plt.figure(figsize=(24,8))\n",
        "     ax1=fig.add_subplot(3,1,1)\n",
        "     ax1.plot(emg6[(i-2)*20000:i*20000],color='black')\n",
        "     ax1.set_xlim(0,40000)\n",
        "     ax1.set_ylim(-4100,4100)\n",
        "\n",
        "     ax2=fig.add_subplot(3,1,2)\n",
        "     ax2.plot(c2[(i-2)*20000:i*20000],color='black')\n",
        "     ax2.set_xlim(0,40000)\n",
        "     ax2.set_ylim(-4100,4100)\n",
        "     \n",
        "     ax3=fig.add_subplot(3,1,3)\n",
        "     power = scaled_features_df.iloc[0:20,(i-2)*20:i*20]\n",
        "     ax3=sns.heatmap(power,vmin=0,vmax=1,cmap=\"gray\",square=True).invert_yaxis()\n",
        "     #plt.savefig('emg&eeg44#'+'h'+str(p)+'m'+str(r)+'e'+str(rownum)+'.png') \n",
        "     plt.savefig(file_png +'/EMG&EEG&EEGs'+'i'+str(z)+'.png')\n",
        "     if i == long_epoch-1 :\n",
        "         plot_e.delete(0, END)\n",
        "         plot_e.insert(0,'the plot is finished')\n",
        "     plt.clf()\n",
        "     plt.close()\n",
        "\n",
        "\n",
        "plot_b1= tk.Button(tab1, text=\"plot\\nEMG&EEGs\",font=(\"arial\", 8, \"italic\"),width=20,height=5,borderwidth=15,command = lambda: plot1(png_folder))\n",
        "plot_b2= tk.Button(tab1, text=\"plot\\nEMG&EEG\",font=(\"arial\", 8, \"italic\"),width=20,height=5,borderwidth=15,command = lambda: plot2(png_folder))\n",
        "plot_b3= tk.Button(tab1, text=\"plot\\nEMG&EEG&EEGs\",font=(\"arial\", 8, \"italic\"),width=20,height=5,borderwidth=15,command = lambda: plot3(png_folder))\n",
        "\n",
        "\n",
        "plot_b1.grid(row=10, column=0)\n",
        "plot_b2.grid(row=10, column=1)\n",
        "plot_b3.grid(row=10, column=2)\n",
        "\n",
        "\n",
        "plot_e = tk.Entry(tab1, width=100, borderwidth=10)\n",
        "plot_e.grid(row=11, column=1)\n",
        "\n",
        "\n",
        "'''\n",
        "the floowing is the 2rd page of train section\n",
        "'''\n",
        "\n",
        "tab2=tk.Frame(tab_main)\n",
        "tab2.place(x=100,y=30)\n",
        "tab_main.add(tab2,text='train')\n",
        "\n",
        "\n",
        "def open_folder2():\n",
        "    global Folderpath2\n",
        "    Folderpath2 = filedialog.askdirectory(title = \"select the folder\",initialdir ='C:/')\n",
        "    print (Folderpath2)\n",
        "    dataset_e.insert(0,Folderpath2)\n",
        "\n",
        "    \n",
        "    \n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def dataset_create():\n",
        "    global data_dir\n",
        "    data_dir=dataset_e.get()\n",
        "    data_root=pathlib.Path(data_dir)\n",
        "    print(data_root)\n",
        "    for item in data_root.iterdir():\n",
        "        print(item)\n",
        "    global all_image_path\n",
        "    all_image_path=list(data_root.glob('*/*'))\n",
        "    len(all_image_path)\n",
        "    all_image_path=[str(path)for path in all_image_path]\n",
        "    random.shuffle(all_image_path)\n",
        "    global image_count\n",
        "    image_count= len(all_image_path)\n",
        "    label_name=sorted(item.name for item in data_root.glob('*/'))\n",
        "    label_to_index=dict((name,index) for index,name in enumerate(label_name))\n",
        "    global all_image_label\n",
        "    all_image_label=[label_to_index[pathlib.Path(p).parent.name]for p in all_image_path]\n",
        "    index_to_label=dict((v,k) for k,v in label_to_index.items())\n",
        "    print(index_to_label)\n",
        "    def load_preprosess_image(img_path):\n",
        "        img_raw=tf.io.read_file(img_path)\n",
        "        img_tensor=tf.image.decode_png(img_raw,channels=3)\n",
        "        img_tensor=tf.image.resize(img_tensor,[256,256])\n",
        "        img_tensor=tf.cast(img_tensor,tf.float32)\n",
        "        img=img_tensor/255\n",
        "        return img    \n",
        "    \n",
        "    path_ds= tf.data.Dataset.from_tensor_slices(all_image_path)\n",
        "    global image_dataset\n",
        "    image_dataset=path_ds.map(load_preprosess_image)\n",
        "    global label_dataset\n",
        "    label_dataset=tf.data.Dataset.from_tensor_slices(all_image_label)\n",
        "    global dataset\n",
        "    dataset=tf.data.Dataset.zip((image_dataset,label_dataset))\n",
        "    print('END')\n",
        "    global test_count\n",
        "    test_count=int(image_count*0.2)\n",
        "    global train_count\n",
        "    train_count=image_count-test_count\n",
        "    global train_dataset\n",
        "    train_dataset=dataset.skip(test_count)\n",
        "    global test_dataset\n",
        "    test_dataset=dataset.take(test_count)\n",
        "    global BATCH_SIZE\n",
        "    BATCH_SIZE=16\n",
        "    print('END*2')\n",
        "    #global train_dataset \n",
        "    train_dataset=train_dataset.shuffle(buffer_size=train_count).batch(BATCH_SIZE).repeat(1000)\n",
        "    #global test_dataset\n",
        "    test_dataset=test_dataset.batch(BATCH_SIZE)\n",
        "    print('END*3')\n",
        "    conform_e.insert(0,'①　preprossing is finished')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def model_formation():\n",
        "    global model\n",
        "    model=tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(32,(3,3),input_shape=(256,256,3),activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(32,(3,3),activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D())\n",
        "    model.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D())\n",
        "    model.add(tf.keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D())\n",
        "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "    model.add(tf.keras.layers.Dense(256,activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(3,activation='softmax'))\n",
        "    print(model.summary())\n",
        "    print('END*4')\n",
        "    conform_e.delete(0, END)\n",
        "    conform_e.insert(0,'②　creating is finished')\n",
        "    return model\n",
        "\n",
        "\n",
        "def comile_model(model):\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'] )\n",
        "    global steps_per_epoch\n",
        "    steps_per_epoch=train_count//BATCH_SIZE\n",
        "    global validation_steps\n",
        "    validation_steps=test_count//BATCH_SIZE\n",
        "    print('END*5')\n",
        "    conform_e.delete(0, END)\n",
        "    conform_e.insert(0,'③　compiling is finished')\n",
        "    return\n",
        "\n",
        "\n",
        "def train():\n",
        "    global N\n",
        "    N = int(epoch_e.get())\n",
        "    global history\n",
        "    history=model.fit(train_dataset,epochs=N,\n",
        "                  steps_per_epoch=steps_per_epoch,\n",
        "                  validation_data=test_dataset,\n",
        "                  validation_steps=validation_steps\n",
        "                )\n",
        "    conform_e.delete(0, END)\n",
        "    conform_e.insert(0,'④　the train is over')\n",
        "\n",
        "    print(history.history.keys())\n",
        "\n",
        "\n",
        "def open_folder3():\n",
        "    global Folderpath3\n",
        "    Folderpath3 = filedialog.askdirectory(title = \"select the folder\",initialdir ='C:/')\n",
        "    print (Folderpath3)\n",
        "    savefolder_e.insert(0,Folderpath3)\n",
        "    \n",
        "    start_time3 = datetime.datetime.now()\n",
        "    global start_time_str3\n",
        "    start_time_str3 = str(start_time3)\n",
        "    \n",
        "    start_time_str3 = start_time_str3.replace(':','-')\n",
        "    start_time_str3 =start_time_str3[:19]\n",
        "    global train_record_folder\n",
        "    train_record_folder = Folderpath3 + '/train_record'+ start_time_str3\n",
        "    print(train_record_folder)\n",
        "    print(train_record_folder)\n",
        "    print(train_record_folder)\n",
        "    print(train_record_folder)\n",
        "    print(train_record_folder)\n",
        "    print(train_record_folder)\n",
        "    return train_record_folder\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_new_file2(path):\n",
        "    \n",
        "    folder = os.path.exists(path)\n",
        "    if not folder:\n",
        "        os.makedirs(path)\n",
        "        print('new')\n",
        "    else:\n",
        "        print('already')\n",
        "        \n",
        "    conform_e.delete(0, END)\n",
        "    conform_e.insert(0,'⑤ the train record folder   ['+ train_record_folder + ']   has been created just now')\n",
        "    \n",
        "    \n",
        "    print(path)\n",
        "    print(path)\n",
        "    print(path+'/')\n",
        "    \n",
        "    \n",
        "    \n",
        "    #savefolder_e.insert(0,'your folder has been created just now')\n",
        "    \n",
        "\n",
        "\n",
        "###  X:/GUI_GtxSleepNet/train_record2021-01-27 21021051\n",
        "def plot_his():\n",
        "#    plt.plot(history.epoch, history.history.get('acc'),label='acc')\n",
        "#    plt.plot(history.epoch, history.history.get('val_acc'),label='val_acc')\n",
        "#    plt.legend()\n",
        "##    plt.savefig(str(train_record_folder) + '/'+'train_timesacc'+'.png')\n",
        " #   \n",
        " #   plt.plot(history.epoch, history.history.get('loss'),label='loss')\n",
        " #   plt.plot(history.epoch, history.history.get('val_loss'),label='val_loss')\n",
        " #   plt.legend()\n",
        " #   plt.savefig(str(train_record_folder) + '/'+'train_timesloss'+'.png')\n",
        "    \n",
        "    model.save(str(train_record_folder) + '/' +'train_times'+'.h5' )\n",
        "\n",
        "    conform_e.delete(0, END)\n",
        "    conform_e.insert(0,'⑥　the record has been saved')\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "dataset_label = tk.Label(tab2,text = 'the dataset folder you have prepared')\n",
        "dataset_label .grid(row =0,column = 0)\n",
        "\n",
        "\n",
        "b_dataset= tk.Button(tab2, text=\"select the dataset folder\",width=25,command = open_folder2)\n",
        "b_dataset.grid(row=0, column=3)\n",
        "\n",
        "dataset_e = tk.Entry(tab2, width=100, borderwidth=10)\n",
        "dataset_e.grid(row=0, column=1)\n",
        "\n",
        "\n",
        "createdataset_b = tk.Button(tab2, text=\"①　preprossing\",width=25,height=2,borderwidth=15,command = dataset_create)\n",
        "createdataset_b.grid(row=1, column=0,columnspan=3)\n",
        "\n",
        "model_b = tk.Button(tab2, text=\"②　create the Model\",width=25,height=2,borderwidth=15,command = model_formation)\n",
        "model_b.grid(row=2, column=0,columnspan=3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "comile_b = tk.Button(tab2, text=\"③　compile the model\",width=25,height=2,borderwidth=15,command = lambda: comile_model(model))\n",
        "comile_b.grid(row=3, column=0,columnspan=3)\n",
        "\n",
        "\n",
        "epoch_e = tk.Entry(tab2, width=100, borderwidth=10)\n",
        "epoch_e.grid(row=4, column=1)\n",
        "\n",
        "\n",
        "train_b = tk.Button(tab2, text=\"④　train the network\",width=25,height=2,borderwidth=15,command = train)\n",
        "train_b.grid(row=5, column=0,columnspan=3)\n",
        "\n",
        "\n",
        "epoch_label = tk.Label(tab2,text = 'the epochs you want to trian ')\n",
        "epoch_label .grid(row =4,column = 0)\n",
        "\n",
        "\n",
        "dataset_label = tk.Label(tab2,text = 'the folder to save train record ')\n",
        "dataset_label .grid(row =6,column = 0)\n",
        "\n",
        "b_savefolder= tk.Button(tab2, text=\"select the folder \",width=25,command = open_folder3)\n",
        "b_savefolder.grid(row=6, column=3)\n",
        "\n",
        "savefolder_e = tk.Entry(tab2, width=100, borderwidth=10)\n",
        "savefolder_e.grid(row=6, column=1)\n",
        "\n",
        "\n",
        "create_new_file_b = tk.Button(tab2, text=\"⑤ create record folder\",width=25,height=2,borderwidth=15,command = lambda: create_new_file2(train_record_folder))\n",
        "create_new_file_b.grid(row=7, column=0,columnspan=3)\n",
        "\n",
        "\n",
        "saverecord_b = tk.Button(tab2, text=\"⑥　save train h5 record\",width=25,height=2,borderwidth=15,command = plot_his)\n",
        "saverecord_b.grid(row=8, column=0,columnspan=3)\n",
        "\n",
        "conform_e = tk.Entry(tab2, width=100,borderwidth=15)\n",
        "conform_e.grid(row=9, column=1)\n",
        "\n",
        "\n",
        "\n",
        "tab3=tk.Frame(tab_main)\n",
        "tab3.place(x=100,y=30)\n",
        "\n",
        "tab_main.add(tab3,text='SleepStagePlot')\n",
        "path = tk.StringVar()\n",
        "\n",
        "from tkinter.filedialog import askdirectory\n",
        "\n",
        "\n",
        "\n",
        "def open_fileh5():\n",
        "    global filepathh5\n",
        "    filepathh5 = filedialog.askopenfilename( )\n",
        "    print (filepathh5)\n",
        "    h5_e.insert(0,filepathh5)\n",
        "    return\n",
        "\n",
        "\n",
        "def SelectPath():\n",
        "    path_ = askdirectory()\n",
        "    path.set(path_)\n",
        "    \n",
        "\n",
        "def pre():\n",
        "    data_dir=predict_e.get()\n",
        "    global predict_root\n",
        "    predict_root=pathlib.Path(data_dir)\n",
        "    for item in predict_root.iterdir():\n",
        "        print(item)\n",
        "    global all_image_path    \n",
        "    all_predict_path=list( predict_root.glob('*/'))\n",
        "    print(all_predict_path)\n",
        "    print(len(all_predict_path))\n",
        "    def load_preprosess_image(img_path):\n",
        "        img_raw=tf.io.read_file(img_path)\n",
        "        img_tensor=tf.image.decode_png(img_raw,channels=3)\n",
        "        img_tensor=tf.image.resize(img_tensor,[256,256])\n",
        "        img_tensor=tf.cast(img_tensor,tf.float32)\n",
        "        img=img_tensor/255\n",
        "        return img\n",
        "    all_predict_path=[str(path)for path in all_predict_path]\n",
        "    predict_path_ds= tf.data.Dataset.from_tensor_slices(all_predict_path)\n",
        "    predict_dataset=predict_path_ds.map(load_preprosess_image)\n",
        "    global Pre\n",
        "    \n",
        "    h5_dir = h5_e.get()\n",
        "    model=tf.keras.models.load_model(h5_dir)\n",
        "\n",
        "    Pre=model.predict(predict_dataset.batch(16))\n",
        "    print(Pre)\n",
        "    print(np.argmax(Pre, axis=1))\n",
        "    global stage_np\n",
        "    stage_np=np.argmax(Pre, axis=1)\n",
        "    print(stage_np)\n",
        "    stage_df=pd.DataFrame(stage_np)\n",
        "    stage_df.to_csv(\"stage.csv\")\n",
        "    \n",
        "    label2 = tk.Label(tab3, text = 'the train is ending')\n",
        "    label2 .grid(row =1,column = 0)\n",
        "\n",
        "\n",
        "def plotplot():\n",
        "    plt.figure(figsize=(100,8))\n",
        "    plt.plot(stage_np,color='black')\n",
        "    plt.savefig('hhh.png')\n",
        "\n",
        "\n",
        "\n",
        "h5_label = tk.Label(tab3,text = 'the h5 file you saved')\n",
        "h5_label .grid(row =0,column = 0)\n",
        "\n",
        "\n",
        "h5_b= tk.Button(tab3, text=\"select the h5 file\",width=25,command = open_fileh5)\n",
        "h5_b.grid(row=0, column=2)\n",
        "\n",
        "h5_e = tk.Entry(tab3, width=100, borderwidth=10)\n",
        "h5_e.grid(row=0, column=1)\n",
        "\n",
        "\n",
        "label_p = tk.Label(tab3,text = 'the folder you want to predict')\n",
        "label_p .grid(row =1,column = 0)\n",
        "\n",
        "predict_e = tk.Entry(tab3,textvariable = path,width=100, borderwidth=10)\n",
        "predict_e.grid(row =1,column = 1)\n",
        "\n",
        "predict_b =tk.Button(tab3,text = 'select the folder',width=25,command = SelectPath)\n",
        "predict_b.grid(row = 1,column = 2)\n",
        "\n",
        "b2 =tk.Button(tab3,text = 'predict',font=(\"arial\", 15, \"italic\"),width=10,height=2,borderwidth=10,command = pre)\n",
        "b2.grid(row = 2,column = 1)\n",
        "\n",
        "b3 =tk.Button(tab3,text = 'ploting',font=(\"arial\", 15, \"italic\"),width=10,height=2,borderwidth=10,command = plotplot)\n",
        "b3.grid(row = 3,column = 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "tab3=tk.Frame(tab_main)\n",
        "tab3.place(x=100,y=30)\n",
        "tab_main.add(tab4,text=''page4)\n",
        "fig = plt.figure(figsize=(7,4),dpi=100)\n",
        "f_plot =fig.add_subplot(111)\n",
        "canvas_spice = FigureCanvasTkAgg(fig,tab3)\n",
        "canvas_spice.get_tk_widget().place(relx=0.3,rely=0.1)\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "root.mainloop()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}